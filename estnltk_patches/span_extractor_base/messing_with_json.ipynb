{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Dict\n",
    "from typing import AnyStr\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "data = [{'id': 822, 'annotations': [{'id': 93, 'completed_by': 1, 'result': [{\"value\":{\"choices\":[\"good\"]},\"id\":\"5T-w7gAwjL\",\"from_name\":\"review\",\"to_name\":\"text\",\"type\":\"choices\",\"origin\":\"manual\"}, {\"value\":{\"start\":39,\"end\":51,\"text\":\"depressiooni\",\"labels\":[\"B-SYMP\"]},\"id\":\"MyYyHuboiz\",\"from_name\":\"label\",\"to_name\":\"text\",\"type\":\"labels\",\"origin\":\"prediction\"}, {'value': {'start': 27, 'end': 32, 'text': '2008a', 'labels': ['dates_numbers']}, 'id': 'gvDXKolt6s', 'from_name': 'label', 'to_name': 'text', 'type': 'labels', 'origin': 'prediction'}, {'value': {'start': 62, 'end': 63, 'text': '4', 'labels': ['dates_numbers']}, 'id': 'HUKZPFELOv', 'from_name': 'label', 'to_name': 'text', 'type': 'labels', 'origin': 'prediction'}, {'value': {'start': 72, 'end': 74, 'text': '10', 'labels': ['dates_numbers']}, 'id': '7B8c5CwReY', 'from_name': 'label', 'to_name': 'text', 'type': 'labels', 'origin': 'prediction'}, {'value': {'start': 69, 'end': 73, 'text': 'st 1', 'labels': ['stages']}, 'id': 'UPknXMsTWD', 'from_name': 'label', 'to_name': 'text', 'type': 'labels', 'origin': 'prediction'}, {'value': {'start': 73, 'end': 76, 'text': '0st', 'labels': ['stages']}, 'id': 'z9vm9HP8Dy', 'from_name': 'label', 'to_name': 'text', 'type': 'labels', 'origin': 'prediction'}, {'value': {'start': 83, 'end': 87, 'text': 'IIA ', 'labels': ['stages']}, 'id': 'NHSHNBzZ25', 'from_name': 'label', 'to_name': 'text', 'type': 'labels', 'origin': 'prediction'}], 'was_cancelled': False, 'ground_truth': False, 'created_at': '2022-02-07T07:45:09.857634Z', 'updated_at': '2022-02-07T07:45:09.857671Z', 'lead_time': 1.208, 'prediction': {}, 'result_count': 0, 'task': 822, 'parent_prediction': 580, 'parent_annotation': None}], 'file_upload': '520c36a2-testmultipletaggers.tsv', 'drafts': [], 'predictions': [580], 'data': {'text': 'Minu vanemad kasvasid üles 2008a aasta depressiooni ajal, kus 4 inimest 10st surid IIA kasvajasse'}, 'meta': {}, 'created_at': '2022-01-26T09:09:51.583992Z', 'updated_at': '2022-01-26T09:09:51.584031Z', 'project': 7}, {'id': 823, 'annotations': [{'id': 94, 'completed_by': 1, 'result': [{'value': {'start': 0, 'end': 4, 'text': 'IIA ', 'labels': ['stages']}, 'id': 'qAqpTYKB6g', 'from_name': 'label', 'to_name': 'text', 'type': 'labels', 'origin': 'prediction'}], 'was_cancelled': False, 'ground_truth': False, 'created_at': '2022-02-07T07:45:11.817270Z', 'updated_at': '2022-02-07T07:45:11.817317Z', 'lead_time': 0.786, 'prediction': {}, 'result_count': 0, 'task': 823, 'parent_prediction': 581, 'parent_annotation': None}], 'file_upload': '4ab7e429-testmultipletaggers.tsv', 'drafts': [], 'predictions': [581], 'data': {'text': 'IIA vähk ei ole mingi naljaasi'}, 'meta': {}, 'created_at': '2022-02-01T13:01:06.718459Z', 'updated_at': '2022-02-01T13:01:06.718489Z', 'project': 7}, {'id': 826, 'annotations': [{'id': 92, 'completed_by': 1, 'result': [{'value': {'start': 55, 'end': 63, 'text': '29.04.10', 'labels': ['dates_numbers']}, 'id': 'c5qnRJzcwS', 'from_name': 'label', 'to_name': 'text', 'type': 'labels', 'origin': 'prediction'}, {'value': {'start': 91, 'end': 92, 'text': '2', 'labels': ['dates_numbers']}, 'id': 'KLpoosE4HN', 'from_name': 'label', 'to_name': 'text', 'type': 'labels', 'origin': 'prediction'}, {'value': {'start': 93, 'end': 94, 'text': '3', 'labels': ['dates_numbers']}, 'id': 'GzYa7ZlbJW', 'from_name': 'label', 'to_name': 'text', 'type': 'labels', 'origin': 'prediction'}, {'value': {'start': 95, 'end': 96, 'text': '0', 'labels': ['dates_numbers']}, 'id': 'kh6gNfgrq0', 'from_name': 'label', 'to_name': 'text', 'type': 'labels', 'origin': 'prediction'}, {'value': {'start': 114, 'end': 124, 'text': '26.03.2011', 'labels': ['dates_numbers']}, 'id': 'vLlSWXyFMb', 'from_name': 'label', 'to_name': 'text', 'type': 'labels', 'origin': 'prediction'}, {'value': {'start': 244, 'end': 246, 'text': '11', 'labels': ['dates_numbers']}, 'id': '7kfjyeHqbg', 'from_name': 'label', 'to_name': 'text', 'type': 'labels', 'origin': 'prediction'}, {'value': {'start': 265, 'end': 270, 'text': '2012a', 'labels': ['dates_numbers']}, 'id': 'HSTLoGG8Ee', 'from_name': 'label', 'to_name': 'text', 'type': 'labels', 'origin': 'prediction'}, {'value': {'start': 89, 'end': 96, 'text': ' T2N3M0', 'labels': ['stages']}, 'id': 'KNTXl3m4ih', 'from_name': 'label', 'to_name': 'text', 'type': 'labels', 'origin': 'prediction'}, {'value': {'start': 172, 'end': 176, 'text': 'IIA ', 'labels': ['stages']}, 'id': 'Fm2FjNxK2D', 'from_name': 'label', 'to_name': 'text', 'type': 'labels', 'origin': 'prediction'}], 'was_cancelled': False, 'ground_truth': False, 'created_at': '2022-02-07T07:45:04.301801Z', 'updated_at': '2022-02-07T07:45:04.301835Z', 'lead_time': 9.777, 'prediction': {}, 'result_count': 0, 'task': 826, 'parent_prediction': 584, 'parent_annotation': None}], 'file_upload': '4ab7e429-testmultipletaggers.tsv', 'drafts': [], 'predictions': [584], 'data': {'text': 'Patsiendil esines eelmisel külastusel, mis leidis aset 29.04.10 tõsiseid tüsistusi seoses T2N3M0 kasvajaga kõhus. 26.03.2011 andis ta teada, et enam ei taha elada. Eks see IIA vähk ei ole tore asi. Patsiendist jääb järele koer Isabella, kes on 11 aastane kutsikas. 2012a tahaks talle kodu leida.'}, 'meta': {}, 'created_at': '2022-02-01T13:01:06.718639Z', 'updated_at': '2022-02-07T07:03:02.722761Z', 'project': 7}, {'id': 827, 'annotations': [{'id': 95, 'completed_by': 1, 'result': [{'value': {'start': 27, 'end': 32, 'text': '2008a', 'labels': ['dates_numbers']}, 'id': 'C3ZSrJ3Nuw', 'from_name': 'label', 'to_name': 'text', 'type': 'labels', 'origin': 'prediction'}, {'value': {'start': 62, 'end': 63, 'text': '4', 'labels': ['dates_numbers']}, 'id': 'yqLtSkOTJh', 'from_name': 'label', 'to_name': 'text', 'type': 'labels', 'origin': 'prediction'}, {'value': {'start': 72, 'end': 74, 'text': '10', 'labels': ['dates_numbers']}, 'id': 'gieLXbyTUI', 'from_name': 'label', 'to_name': 'text', 'type': 'labels', 'origin': 'prediction'}, {'value': {'start': 69, 'end': 73, 'text': 'st 1', 'labels': ['stages']}, 'id': 'tbQABAgngr', 'from_name': 'label', 'to_name': 'text', 'type': 'labels', 'origin': 'prediction'}, {'value': {'start': 73, 'end': 76, 'text': '0st', 'labels': ['stages']}, 'id': 'f8ZSjdJKMS', 'from_name': 'label', 'to_name': 'text', 'type': 'labels', 'origin': 'prediction'}, {'value': {'start': 83, 'end': 87, 'text': 'IIA ', 'labels': ['stages']}, 'id': 'mF5qa7lGqL', 'from_name': 'label', 'to_name': 'text', 'type': 'labels', 'origin': 'prediction'}], 'was_cancelled': False, 'ground_truth': False, 'created_at': '2022-02-07T07:45:17.656135Z', 'updated_at': '2022-02-07T07:45:17.656172Z', 'lead_time': 1.369, 'prediction': {}, 'result_count': 0, 'task': 827, 'parent_prediction': 586, 'parent_annotation': None}], 'file_upload': '4ab7e429-testmultipletaggers.tsv', 'drafts': [], 'predictions': [586], 'data': {'text': 'Minu vanemad kasvasid üles 2008a aasta depressiooni ajal, kus 4 inimest 10st surid IIA kasvajasse'}, 'meta': {}, 'created_at': '2022-02-01T13:01:06.718686Z', 'updated_at': '2022-02-01T13:01:06.718698Z', 'project': 7}]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "json_data = json.dumps(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minu set()\n",
      "vanemad set()\n",
      "kasvasid set()\n",
      "üles set()\n",
      "2008a {'dates_numbers'}\n",
      "aasta set()\n",
      "depressiooni {'B-SYMP'}\n",
      "ajal set()\n",
      ", set()\n",
      "kus set()\n",
      "4 {'dates_numbers'}\n",
      "inimest {'stages'}\n",
      "10st {'stages', 'dates_numbers'}\n",
      "surid set()\n",
      "IIA {'stages'}\n",
      "kasvajasse set()\n",
      "IIA {'stages'}\n",
      "vähk set()\n",
      "ei set()\n",
      "ole set()\n",
      "mingi set()\n",
      "naljaasi set()\n",
      "Patsiendil set()\n",
      "esines set()\n",
      "eelmisel set()\n",
      "külastusel set()\n",
      ", set()\n",
      "mis set()\n",
      "leidis set()\n",
      "aset set()\n",
      "29 {'dates_numbers'}\n",
      ". {'dates_numbers'}\n",
      "04 {'dates_numbers'}\n",
      ". {'dates_numbers'}\n",
      "10 {'dates_numbers'}\n",
      "tõsiseid set()\n",
      "tüsistusi set()\n",
      "seoses set()\n",
      "T2N3M0 {'stages', 'dates_numbers'}\n",
      "kasvajaga set()\n",
      "kõhus set()\n",
      ". set()\n",
      "26 {'dates_numbers'}\n",
      ". {'dates_numbers'}\n",
      "03 {'dates_numbers'}\n",
      ". {'dates_numbers'}\n",
      "2011 {'dates_numbers'}\n",
      "andis set()\n",
      "ta set()\n",
      "teada set()\n",
      ", set()\n",
      "et set()\n",
      "enam set()\n",
      "ei set()\n",
      "taha set()\n",
      "elada set()\n",
      ". set()\n",
      "Eks set()\n",
      "see set()\n",
      "IIA {'stages'}\n",
      "vähk set()\n",
      "ei set()\n",
      "ole set()\n",
      "tore set()\n",
      "asi set()\n",
      ". set()\n",
      "Patsiendist set()\n",
      "jääb set()\n",
      "järele set()\n",
      "koer set()\n",
      "Isabella set()\n",
      ", set()\n",
      "kes set()\n",
      "on set()\n",
      "11 {'dates_numbers'}\n",
      "aastane set()\n",
      "kutsikas set()\n",
      ". set()\n",
      "2012a {'dates_numbers'}\n",
      "tahaks set()\n",
      "talle set()\n",
      "kodu set()\n",
      "leida set()\n",
      ". set()\n",
      "Minu set()\n",
      "vanemad set()\n",
      "kasvasid set()\n",
      "üles set()\n",
      "2008a {'dates_numbers'}\n",
      "aasta set()\n",
      "depressiooni set()\n",
      "ajal set()\n",
      ", set()\n",
      "kus set()\n",
      "4 {'dates_numbers'}\n",
      "inimest {'stages'}\n",
      "10st {'stages', 'dates_numbers'}\n",
      "surid set()\n",
      "IIA {'stages'}\n",
      "kasvajasse set()\n"
     ]
    }
   ],
   "source": [
    "from estnltk import Layer, Text, Span, BaseSpan, ElementaryBaseSpan\n",
    "import csv\n",
    "\n",
    "\n",
    "class PredictionResults:\n",
    "    def __init__(self, tasks, bert_annotations: List[AnyStr]):\n",
    "        self.tasks = tasks\n",
    "        self.entries = []\n",
    "        self.bert_annotations = bert_annotations\n",
    "\n",
    "        for task in self.tasks:\n",
    "            results_entry = ResultsEntry(entry=task, bert_annotations=self.bert_annotations)\n",
    "            self.entries.append(results_entry)\n",
    "\n",
    "    def make_training_file(self):\n",
    "        f_finetuning_training_data = open('fine_tuning_training.tsv', 'w')\n",
    "        writer = csv.writer(f_finetuning_training_data, delimiter='\\t')\n",
    "        writer.writerow(['text', 'y'])\n",
    "\n",
    "        for entry in self.entries:\n",
    "            for k, v in entry.tokenized().items():\n",
    "                word = v[0]\n",
    "                annotations = v[1]\n",
    "                print(word, annotations)\n",
    "                for annot in annotations:\n",
    "                    if annot in self.bert_annotations:\n",
    "                        writer.writerow([word, annot])\n",
    "                        continue\n",
    "                    writer.writerow([word, \"0\"])\n",
    "                if len(annotations) == 0:\n",
    "                    writer.writerow([word, \"0\"])\n",
    "\n",
    "        f_finetuning_training_data.close()\n",
    "\n",
    "\n",
    "class ResultsEntry:\n",
    "    def __init__(self, entry: Dict[AnyStr, List], bert_annotations: List[AnyStr]):\n",
    "        self.raw_text = entry['data']['text']\n",
    "        self.text = Text(entry['data']['text'])\n",
    "        self.id = entry['id']\n",
    "        self.choice = None\n",
    "        self.bert_annotations = bert_annotations\n",
    "\n",
    "        for span in entry['annotations'][0]['result']:\n",
    "            if 'choices' in span['value']:\n",
    "                if span['value']['choices'][0] == 'good':\n",
    "                    self.choice = True\n",
    "                elif span['value']['choices'][0] == 'bad':\n",
    "                    self.choice = False\n",
    "\n",
    "            elif 'labels' in span['value']:\n",
    "                start = span['value']['start']\n",
    "                end = span['value']['end']\n",
    "                span_text = span['value']['text']\n",
    "                labels = span['value']['labels']\n",
    "\n",
    "                for label in labels:\n",
    "                    if label in self.bert_annotations:\n",
    "                        new_layer = Layer(name='ner', attributes=['grammar_symbol', 'value'], text_object=None)\n",
    "                    else:\n",
    "                        new_layer = Layer(name=label, attributes=['grammar_symbol', 'value'], text_object=None)\n",
    "                    if new_layer.name in self.text.layers:\n",
    "                        self.text[label].add_annotation(ElementaryBaseSpan(start=int(start), end=int(end)),\n",
    "                                                        **{'grammar_symbol': label, 'value': span_text})\n",
    "                    elif new_layer.name not in self.text.layers:\n",
    "                        new_layer.add_annotation(\n",
    "                        ElementaryBaseSpan(start=int(start), end=int(end)),\n",
    "                        **{'grammar_symbol': label, 'value': span_text}\n",
    "                        )\n",
    "\n",
    "                        self.text.add_layer(new_layer)\n",
    "\n",
    "    def tokenized(self):\n",
    "        return tokenize_for_training(self.text)\n",
    "\n",
    "\n",
    "\n",
    "def tokenize_for_training(text: Text):\n",
    "    estnltk_tokenizer.tag(text)\n",
    "\n",
    "    tokens_and_spans = {(span.start, span.end):[span.text, set()] for span in text.tokens}\n",
    "    for layer in text.list_layers():\n",
    "        if layer.name != 'tokens':\n",
    "            for span in layer:\n",
    "                # print(span.annotations, span.start, span.end)\n",
    "                grammar_symbol = span.annotations[0]['grammar_symbol']\n",
    "                start = span.start\n",
    "                end = span.end\n",
    "\n",
    "                # print(layer.name, span.text, span.start, span.end)\n",
    "                for k, v in tokens_and_spans.items():\n",
    "                    # print(k, v, span.annotations) # -> Minu [0, 4]\n",
    "                    # if len(range(max(span.start, span_.start), min(span.end, span_.end))) > 0\n",
    "                    start_ = k[0]\n",
    "                    end_ = k[1]\n",
    "\n",
    "                    if len(range(max(start, start_), min(end, end_))) > 0 and len(grammar_symbol) > 0:\n",
    "                        # print(grammar_symbol)\n",
    "                        # print(start, start_, end, end_)\n",
    "\n",
    "                        tokens_and_spans[k][1] = v[1].union([grammar_symbol])\n",
    "\n",
    "    return tokens_and_spans\n",
    "\n",
    "\n",
    "\n",
    "# testentry = ResultsEntry(data[0], bert_annotations=['B-SYMP', 'B-DRUG'])\n",
    "# testdata = tokenizeForTraining(testentry.text)\n",
    "\n",
    "\n",
    "data = [{'id': 822, 'annotations': [{'id': 93, 'completed_by': 1, 'result': [{\"value\":{\"choices\":[\"good\"]},\"id\":\"5T-w7gAwjL\",\"from_name\":\"review\",\"to_name\":\"text\",\"type\":\"choices\",\"origin\":\"manual\"}, {\"value\":{\"start\":39,\"end\":51,\"text\":\"depressiooni\",\"labels\":[\"B-SYMP\"]},\"id\":\"MyYyHuboiz\",\"from_name\":\"label\",\"to_name\":\"text\",\"type\":\"labels\",\"origin\":\"prediction\"}, {'value': {'start': 27, 'end': 32, 'text': '2008a', 'labels': ['dates_numbers']}, 'id': 'gvDXKolt6s', 'from_name': 'label', 'to_name': 'text', 'type': 'labels', 'origin': 'prediction'}, {'value': {'start': 62, 'end': 63, 'text': '4', 'labels': ['dates_numbers']}, 'id': 'HUKZPFELOv', 'from_name': 'label', 'to_name': 'text', 'type': 'labels', 'origin': 'prediction'}, {'value': {'start': 72, 'end': 74, 'text': '10', 'labels': ['dates_numbers']}, 'id': '7B8c5CwReY', 'from_name': 'label', 'to_name': 'text', 'type': 'labels', 'origin': 'prediction'}, {'value': {'start': 69, 'end': 73, 'text': 'st 1', 'labels': ['stages']}, 'id': 'UPknXMsTWD', 'from_name': 'label', 'to_name': 'text', 'type': 'labels', 'origin': 'prediction'}, {'value': {'start': 73, 'end': 76, 'text': '0st', 'labels': ['stages']}, 'id': 'z9vm9HP8Dy', 'from_name': 'label', 'to_name': 'text', 'type': 'labels', 'origin': 'prediction'}, {'value': {'start': 83, 'end': 87, 'text': 'IIA ', 'labels': ['stages']}, 'id': 'NHSHNBzZ25', 'from_name': 'label', 'to_name': 'text', 'type': 'labels', 'origin': 'prediction'}], 'was_cancelled': False, 'ground_truth': False, 'created_at': '2022-02-07T07:45:09.857634Z', 'updated_at': '2022-02-07T07:45:09.857671Z', 'lead_time': 1.208, 'prediction': {}, 'result_count': 0, 'task': 822, 'parent_prediction': 580, 'parent_annotation': None}], 'file_upload': '520c36a2-testmultipletaggers.tsv', 'drafts': [], 'predictions': [580], 'data': {'text': 'Minu vanemad kasvasid üles 2008a aasta depressiooni ajal, kus 4 inimest 10st surid IIA kasvajasse'}, 'meta': {}, 'created_at': '2022-01-26T09:09:51.583992Z', 'updated_at': '2022-01-26T09:09:51.584031Z', 'project': 7}, {'id': 823, 'annotations': [{'id': 94, 'completed_by': 1, 'result': [{'value': {'start': 0, 'end': 4, 'text': 'IIA ', 'labels': ['stages']}, 'id': 'qAqpTYKB6g', 'from_name': 'label', 'to_name': 'text', 'type': 'labels', 'origin': 'prediction'}], 'was_cancelled': False, 'ground_truth': False, 'created_at': '2022-02-07T07:45:11.817270Z', 'updated_at': '2022-02-07T07:45:11.817317Z', 'lead_time': 0.786, 'prediction': {}, 'result_count': 0, 'task': 823, 'parent_prediction': 581, 'parent_annotation': None}], 'file_upload': '4ab7e429-testmultipletaggers.tsv', 'drafts': [], 'predictions': [581], 'data': {'text': 'IIA vähk ei ole mingi naljaasi'}, 'meta': {}, 'created_at': '2022-02-01T13:01:06.718459Z', 'updated_at': '2022-02-01T13:01:06.718489Z', 'project': 7}, {'id': 826, 'annotations': [{'id': 92, 'completed_by': 1, 'result': [{'value': {'start': 55, 'end': 63, 'text': '29.04.10', 'labels': ['dates_numbers']}, 'id': 'c5qnRJzcwS', 'from_name': 'label', 'to_name': 'text', 'type': 'labels', 'origin': 'prediction'}, {'value': {'start': 91, 'end': 92, 'text': '2', 'labels': ['dates_numbers']}, 'id': 'KLpoosE4HN', 'from_name': 'label', 'to_name': 'text', 'type': 'labels', 'origin': 'prediction'}, {'value': {'start': 93, 'end': 94, 'text': '3', 'labels': ['dates_numbers']}, 'id': 'GzYa7ZlbJW', 'from_name': 'label', 'to_name': 'text', 'type': 'labels', 'origin': 'prediction'}, {'value': {'start': 95, 'end': 96, 'text': '0', 'labels': ['dates_numbers']}, 'id': 'kh6gNfgrq0', 'from_name': 'label', 'to_name': 'text', 'type': 'labels', 'origin': 'prediction'}, {'value': {'start': 114, 'end': 124, 'text': '26.03.2011', 'labels': ['dates_numbers']}, 'id': 'vLlSWXyFMb', 'from_name': 'label', 'to_name': 'text', 'type': 'labels', 'origin': 'prediction'}, {'value': {'start': 244, 'end': 246, 'text': '11', 'labels': ['dates_numbers']}, 'id': '7kfjyeHqbg', 'from_name': 'label', 'to_name': 'text', 'type': 'labels', 'origin': 'prediction'}, {'value': {'start': 265, 'end': 270, 'text': '2012a', 'labels': ['dates_numbers']}, 'id': 'HSTLoGG8Ee', 'from_name': 'label', 'to_name': 'text', 'type': 'labels', 'origin': 'prediction'}, {'value': {'start': 89, 'end': 96, 'text': ' T2N3M0', 'labels': ['stages']}, 'id': 'KNTXl3m4ih', 'from_name': 'label', 'to_name': 'text', 'type': 'labels', 'origin': 'prediction'}, {'value': {'start': 172, 'end': 176, 'text': 'IIA ', 'labels': ['stages']}, 'id': 'Fm2FjNxK2D', 'from_name': 'label', 'to_name': 'text', 'type': 'labels', 'origin': 'prediction'}], 'was_cancelled': False, 'ground_truth': False, 'created_at': '2022-02-07T07:45:04.301801Z', 'updated_at': '2022-02-07T07:45:04.301835Z', 'lead_time': 9.777, 'prediction': {}, 'result_count': 0, 'task': 826, 'parent_prediction': 584, 'parent_annotation': None}], 'file_upload': '4ab7e429-testmultipletaggers.tsv', 'drafts': [], 'predictions': [584], 'data': {'text': 'Patsiendil esines eelmisel külastusel, mis leidis aset 29.04.10 tõsiseid tüsistusi seoses T2N3M0 kasvajaga kõhus. 26.03.2011 andis ta teada, et enam ei taha elada. Eks see IIA vähk ei ole tore asi. Patsiendist jääb järele koer Isabella, kes on 11 aastane kutsikas. 2012a tahaks talle kodu leida.'}, 'meta': {}, 'created_at': '2022-02-01T13:01:06.718639Z', 'updated_at': '2022-02-07T07:03:02.722761Z', 'project': 7}, {'id': 827, 'annotations': [{'id': 95, 'completed_by': 1, 'result': [{'value': {'start': 27, 'end': 32, 'text': '2008a', 'labels': ['dates_numbers']}, 'id': 'C3ZSrJ3Nuw', 'from_name': 'label', 'to_name': 'text', 'type': 'labels', 'origin': 'prediction'}, {'value': {'start': 62, 'end': 63, 'text': '4', 'labels': ['dates_numbers']}, 'id': 'yqLtSkOTJh', 'from_name': 'label', 'to_name': 'text', 'type': 'labels', 'origin': 'prediction'}, {'value': {'start': 72, 'end': 74, 'text': '10', 'labels': ['dates_numbers']}, 'id': 'gieLXbyTUI', 'from_name': 'label', 'to_name': 'text', 'type': 'labels', 'origin': 'prediction'}, {'value': {'start': 69, 'end': 73, 'text': 'st 1', 'labels': ['stages']}, 'id': 'tbQABAgngr', 'from_name': 'label', 'to_name': 'text', 'type': 'labels', 'origin': 'prediction'}, {'value': {'start': 73, 'end': 76, 'text': '0st', 'labels': ['stages']}, 'id': 'f8ZSjdJKMS', 'from_name': 'label', 'to_name': 'text', 'type': 'labels', 'origin': 'prediction'}, {'value': {'start': 83, 'end': 87, 'text': 'IIA ', 'labels': ['stages']}, 'id': 'mF5qa7lGqL', 'from_name': 'label', 'to_name': 'text', 'type': 'labels', 'origin': 'prediction'}], 'was_cancelled': False, 'ground_truth': False, 'created_at': '2022-02-07T07:45:17.656135Z', 'updated_at': '2022-02-07T07:45:17.656172Z', 'lead_time': 1.369, 'prediction': {}, 'result_count': 0, 'task': 827, 'parent_prediction': 586, 'parent_annotation': None}], 'file_upload': '4ab7e429-testmultipletaggers.tsv', 'drafts': [], 'predictions': [586], 'data': {'text': 'Minu vanemad kasvasid üles 2008a aasta depressiooni ajal, kus 4 inimest 10st surid IIA kasvajasse'}, 'meta': {}, 'created_at': '2022-02-01T13:01:06.718686Z', 'updated_at': '2022-02-01T13:01:06.718698Z', 'project': 7}]\n",
    "\n",
    "results = PredictionResults(tasks=data, bert_annotations=['B-SYMP', 'B-DRUG'])\n",
    "results.make_training_file()\n",
    "# results.entries[0].tokenized()\n",
    "# makeFile(results, 'fine_tuning_training.tsv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True 822 Text(text='Minu vanemad kasvasid üles 2008a aasta depressiooni ajal, kus 4 inimest 10st surid IIA kasvajasse')\n",
      "None 823 Text(text='IIA vähk ei ole mingi naljaasi')\n",
      "None 826 Text(text='Patsiendil esines eelmisel külastusel, mis leidis aset 29.04.10 tõsiseid tüsistusi seoses T2N3M0 kasvajaga kõhus. 26.03.2011 andis ta teada, et enam ei taha elada. Eks see IIA vähk ei ole tore asi. Patsiendist jääb järele koer Isabella, kes on 11 aastane kutsikas. 2012a tahaks talle kodu leida.')\n",
      "None 827 Text(text='Minu vanemad kasvasid üles 2008a aasta depressiooni ajal, kus 4 inimest 10st surid IIA kasvajasse')\n"
     ]
    }
   ],
   "source": [
    "entries = results.entries\n",
    "for entry in entries:\n",
    "    print(entry.choice, entry.id, entry.text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from pipelines.step03_BERT_fine_tuning.dataloaders import Sequences, Tokens\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "data_path = 'tokhor.tsv'\n",
    "dl = Tokens.Tsv(data_path)\n",
    "\n",
    "from datasets import Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "\n",
    "testentry = ResultsEntry(data[0], bert_annotations=['B-SYMP', 'B-DRUG'])\n",
    "\n",
    "# from estnltk_patches.taggers.cancer_stage_tagger.cancer_stage_tagger import CancerStageTagger\n",
    "# from estnltk_patches.taggers.robust_date_number_tagger.robust_date_number_tagger import RobustDateNumberTagger\n",
    "# from estnltk_patches.taggers.ner_tagger.ner_tagger import BertNerTagger\n",
    "#\n",
    "# taggerA = CancerStageTagger()\n",
    "# taggerB = RobustDateNumberTagger()\n",
    "# taggerC = BertNerTagger(model_path='../../medbert_models/token_classifier_model')\n",
    "#\n",
    "# textike = Text('Minu vanemad kasvasid üles 2008a aasta depressiooni ajal, kus 4 inimest 10st surid IIA kasvajasse')\n",
    "#\n",
    "# taggerA(textike)\n",
    "# taggerB(textike)\n",
    "# taggerC(textike)\n",
    "# print(\n",
    "# )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minu vanemad kasvasid üles 2008a aasta depressiooni ajal, kus 4 inimest 10st surid IIA kasvajasse\n",
      "labelstudio predict to estnltk\n",
      "Layer(name='dates_numbers', attributes=('grammar_symbol', 'value'), spans=SL[Span('2008a', [{'grammar_symbol': 'dates_numbers', 'value': '2008a'}]),\n",
      "Span('4', [{'grammar_symbol': 'dates_numbers', 'value': '4'}]),\n",
      "Span('10', [{'grammar_symbol': 'dates_numbers', 'value': '10'}])])\n",
      "Layer(name='ner', attributes=('grammar_symbol', 'value'), spans=SL[Span('depressiooni', [{'grammar_symbol': 'B-SYMP', 'value': 'depressiooni'}])])\n",
      "Layer(name='stages', attributes=('grammar_symbol', 'value'), spans=SL[Span('st 1', [{'grammar_symbol': 'stages', 'value': 'st 1'}]),\n",
      "Span('0st', [{'grammar_symbol': 'stages', 'value': '0st'}]),\n",
      "Span('IIA ', [{'grammar_symbol': 'stages', 'value': 'IIA '}])])\n",
      " VS Originaalsed taggerid ---- \n",
      "Layer(name='dates_numbers', attributes=('grammar_symbol', 'regex_type', 'value', '_priority_'), spans=SL[Span('2008a', [{'grammar_symbol': 'DATE', 'regex_type': 'date8', 'value': '2008a', '_priority_': 0}]),\n",
      "Span('4', [{'grammar_symbol': 'NUMBER', 'regex_type': 'anynumber', 'value': '4', '_priority_': 1}]),\n",
      "Span('10', [{'grammar_symbol': 'NUMBER', 'regex_type': 'anynumber', 'value': '10', '_priority_': 1}])])\n",
      "Layer(name='ner', attributes=('grammar_symbol', 'value'), spans=SL[Span('depressiooni', [{'grammar_symbol': 'B-SYMP', 'value': 'depressiooni'}])])\n",
      "Layer(name='stages', attributes=('grammar_symbol', 'regex_type', 'value', '_priority_'), spans=SL[Span('st 1', [{'grammar_symbol': 'STAGE', 'regex_type': 'r5', 'value': 'I', '_priority_': 0}]),\n",
      "Span('0st', [{'grammar_symbol': 'STAGE', 'regex_type': 'r4', 'value': '0', '_priority_': 0}]),\n",
      "Span('IIA ', [{'grammar_symbol': 'STAGE', 'regex_type': 'r1', 'value': 'IIA', '_priority_': 0}])])\n"
     ]
    }
   ],
   "source": [
    "# first_entry = ResultsEntry(data[0], ['B-SYMP', 'B-DRUG'])\n",
    "#\n",
    "# print(first_entry.raw_text())\n",
    "# print(\"labelstudio predict to estnltk\")\n",
    "# for layer in first_entry.text().list_layers():\n",
    "#     print(layer)\n",
    "# print(\" VS Originaalsed taggerid ---- \")\n",
    "# for layer in textike.list_layers():\n",
    "#     print(layer)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "model_path = '../../medbert_models/token_classifier_model'\n",
    "\n",
    "tokenizer_args = {\n",
    "    \"lowercase\": False\n",
    "}\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, **tokenizer_args)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "['mu',\n '##ist',\n '##se',\n 'ise',\n '##seis',\n '##vuse',\n 'ajal',\n 'avaldus',\n 'eesti',\n 'h',\n '##oi',\n '##mud',\n '##e',\n 'vaimne',\n 'loo',\n '##min',\n '##g',\n 'mitmes',\n '##ugu',\n '##stes',\n 'rahva',\n '##luu',\n '##le',\n 'vormid',\n '##es',\n '.',\n '120',\n '##8',\n '–',\n '27',\n 'sa',\n '##ks',\n '##a',\n 'ord',\n '##uru',\n '##ut',\n '##lite',\n 'ja',\n 'ta',\n '##an',\n '##laste',\n 'vastu',\n 'so',\n '##di',\n '##nud',\n 'eest',\n '##lased',\n 'al',\n '##ista',\n '##ti',\n 'ja',\n 'suru',\n '##ti',\n 'fe',\n '##od',\n '##aali',\n '##kk',\n '##esse',\n '.',\n 'sel',\n 'viisil',\n 'kujunenud',\n 'seisus',\n '##liku',\n '##s',\n 'uh',\n '##is',\n '##konnas',\n 'moodusta',\n '##sid',\n 'eest',\n '##lased',\n 'ko',\n '##ige',\n 'madalama',\n 'seisus',\n '##e',\n '–',\n 'talu',\n '##poeg',\n '##konna',\n '.',\n 'see',\n '##to',\n '##ttu',\n 'oli',\n 'neil',\n 'raske',\n 'omandada',\n 'har',\n '##id',\n '##ust',\n 'ning',\n 'eesti',\n '##keel',\n '##se',\n 'kirjas',\n '##on',\n '##a',\n 'alg',\n '##ata',\n '##mine',\n 'ja',\n 'e',\n '##de',\n '##ndamine',\n 'ja',\n '##i',\n '19',\n '.',\n 'sa',\n '##ja',\n '##ndi',\n '##ni',\n 'vo',\n '##ora',\n '##st',\n 'rah',\n '##vuse',\n '##st',\n '(',\n 'peamiselt']"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strs = \"Muistse iseseisvuse ajal avaldus Eesti hõimude vaimne looming mitmesugustes rahvaluule vormides. 1208–27 Saksa ordurüütlite ja taanlaste vastu sõdinud eestlased alistati ja suruti feodaalikkesse. Sel viisil kujunenud seisuslikus ühiskonnas moodustasid eestlased kõige madalama seisuse – talupoegkonna. Seetõttu oli neil raske omandada haridust ning eestikeelse kirjasõna algatamine ja edendamine jäi 19. sajandini võõrast rahvusest (peamiselt \"\n",
    "tokenizer.tokenize(strs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['paracetamol']\n",
      "['ibuprofen']\n",
      "['dur', '##ax', '##el']\n",
      "['iv', '##erm', '##ect', '##in']\n",
      "['depressiooni']\n"
     ]
    }
   ],
   "source": [
    "ravimid = ['paracetamol', 'ibuprofen', 'Duraxel', 'ivermectin', 'Depressiooni']\n",
    "\n",
    "for i in ravimid:\n",
    "    print(tokenizer.tokenize(i))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "['min', '##a', 'olen', 'veel', 'noor']"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\" \".join(tokenizer.tokenize(testentry.raw_text()))\n",
    "\n",
    "tokenizer.tokenize(\"Mina olen veel noor\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['depressiooni', Span('depressiooni', [{'grammar_symbol': 'B-SYMP', 'value': 'depressiooni'}])]]\n"
     ]
    },
    {
     "data": {
      "text/plain": "(['d'], ['B_e'])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def extractPOS(tagged_text):\n",
    "#     t = tagged_text\n",
    "#     t_pos = t.ner['text','ner']\n",
    "#     print(t_pos)\n",
    "#     new_sentence = []\n",
    "#     new_label = []\n",
    "#     for i, cur_lp  in enumerate(t_pos):\n",
    "#         last_p = None\n",
    "#         nxt_p = None\n",
    "#         if i != 0:\n",
    "#             last_p = t_pos[i-1][0][1]\n",
    "#         if i != len(t_pos)-1:\n",
    "#             nxt_p = t_pos[i+1][0][1]\n",
    "#         cur_p = cur_lp[0][1]\n",
    "#\n",
    "#         new_sentence.append(cur_lp[0][0])\n",
    "#         # Outside\n",
    "#         if cur_p == last_p and cur_p != nxt_p:\n",
    "#             new_label.append(\"O_\" + cur_p)\n",
    "#         # Inside\n",
    "#         elif cur_p == last_p and cur_p == nxt_p:\n",
    "#             new_label.append(\"I_\" + cur_p)\n",
    "#         # Beginning\n",
    "#         else:\n",
    "#             new_label.append(\"B_\" + cur_p)\n",
    "#     return new_sentence, new_label\n",
    "#\n",
    "# extractPOS(testentry.text())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'morph_analysis', 'tokens', 'sentences', 'words', 'compound_tokens'}\n",
      "0 [['Minu', 'P']]\n",
      "1 [['vanemad', 'S']]\n",
      "2 [['kasvasid', 'V']]\n",
      "3 [['üles', 'D']]\n",
      "4 [['2008a', 'N']]\n",
      "5 [['aasta', 'S']]\n",
      "6 [['depressiooni', 'S']]\n",
      "7 [['ajal', 'K']]\n",
      "8 [[',', 'Z']]\n",
      "9 [['kus', 'D']]\n",
      "10 [['4', 'N']]\n",
      "11 [['inimest', 'S']]\n",
      "12 [['10st', 'N']]\n",
      "13 [['surid', 'V']]\n",
      "14 [['IIA', 'I']]\n",
      "15 [['kasvajasse', 'S']]\n"
     ]
    },
    {
     "data": {
      "text/plain": "(['Minu',\n  'vanemad',\n  'kasvasid',\n  'üles',\n  '2008a',\n  'aasta',\n  'depressiooni',\n  'ajal',\n  ',',\n  'kus',\n  '4',\n  'inimest',\n  '10st',\n  'surid',\n  'IIA',\n  'kasvajasse'],\n ['B_P',\n  'B_S',\n  'B_V',\n  'B_D',\n  'B_N',\n  'B_S',\n  'O_S',\n  'B_K',\n  'B_Z',\n  'B_D',\n  'B_N',\n  'B_S',\n  'B_N',\n  'B_V',\n  'B_I',\n  'B_S'])"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing original function\n",
    "\n",
    "# def extractPOS(sentence):\n",
    "#     t = Text(sentence)\n",
    "#     # tagging the object\n",
    "#     t.tag_layer(['words', 'sentences', 'morph_analysis'])\n",
    "#     t_pos = t.morph_analysis['text','partofspeech']\n",
    "#     print(t.layers)\n",
    "#     new_sentence = []\n",
    "#     new_label = []\n",
    "#     for i, cur_lp  in enumerate(t_pos):\n",
    "#         print(i, cur_lp)\n",
    "#         last_p = None\n",
    "#         nxt_p = None\n",
    "#         if i != 0:\n",
    "#             last_p = t_pos[i-1][0][1]\n",
    "#         if i != len(t_pos)-1:\n",
    "#             nxt_p = t_pos[i+1][0][1]\n",
    "#         cur_p = cur_lp[0][1]\n",
    "#\n",
    "#         new_sentence.append(cur_lp[0][0])\n",
    "#         # Outside\n",
    "#         if cur_p == last_p and cur_p != nxt_p:\n",
    "#             new_label.append(\"O_\" + cur_p)\n",
    "#         # Inside\n",
    "#         elif cur_p == last_p and cur_p == nxt_p:\n",
    "#             new_label.append(\"I_\" + cur_p)\n",
    "#         # Beginning\n",
    "#         else:\n",
    "#             new_label.append(\"B_\" + cur_p)\n",
    "#     return new_sentence, new_label\n",
    "#\n",
    "# extractPOS(\"Minu vanemad kasvasid üles 2008a aasta depressiooni ajal, kus 4 inimest 10st surid IIA kasvajasse\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "Layer(name='ner', attributes=('grammar_symbol', 'value'), spans=SL[Span('depressiooni', [{'grammar_symbol': 'B-SYMP', 'value': 'depressiooni'}])])",
      "text/html": "<h4>Layer</h4>\n\n\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>layer name</th>\n      <th>attributes</th>\n      <th>parent</th>\n      <th>enveloping</th>\n      <th>ambiguous</th>\n      <th>span count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>ner</td>\n      <td>grammar_symbol, value</td>\n      <td>None</td>\n      <td>None</td>\n      <td>False</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>text</th>\n      <th>grammar_symbol</th>\n      <th>value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>depressiooni</td>\n      <td>B-SYMP</td>\n      <td>depressiooni</td>\n    </tr>\n  </tbody>\n</table>"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tokenizer.tokenize(testentry.raw_text())\n",
    "\n",
    "testentry.text()['ner']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "from estnltk.taggers.text_segmentation.tokens_tagger import TokensTagger\n",
    "\n",
    "estnltk_tokenizer = TokensTagger()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "outputs": [],
   "source": [
    "# Siin proovin peale covidit\n",
    "from estnltk import Annotation\n",
    "from typing import Set\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "\n",
    "def tokenizeForTraining(text: Text):\n",
    "    estnltk_tokenizer.tag(text)\n",
    "\n",
    "    tokens_and_spans = {(span.start, span.end):[span.text, set()] for span in text.tokens}\n",
    "    # print(tokens_and_spans)\n",
    "\n",
    "    for layer in text.list_layers():\n",
    "        if layer.name != 'tokens':\n",
    "            for span in layer:\n",
    "                # print(span.annotations, span.start, span.end)\n",
    "                grammar_symbol = span.annotations[0]['grammar_symbol']\n",
    "                start = span.start\n",
    "                end = span.end\n",
    "\n",
    "                # print(layer.name, span.text, span.start, span.end)\n",
    "                for k, v in tokens_and_spans.items():\n",
    "                    # print(k, v, span.annotations) # -> Minu [0, 4]\n",
    "                    # if len(range(max(span.start, span_.start), min(span.end, span_.end))) > 0\n",
    "                    start_ = k[0]\n",
    "                    end_ = k[1]\n",
    "\n",
    "                    if len(range(max(start, start_), min(end, end_))) > 0 and len(grammar_symbol) > 0:\n",
    "                        # print(grammar_symbol)\n",
    "                        # print(start, start_, end, end_)\n",
    "\n",
    "                        tokens_and_spans[k][1] = v[1].union([grammar_symbol])\n",
    "\n",
    "    return tokens_and_spans\n",
    "\n",
    "\n",
    "\n",
    "    # for layer in text.list_layers():\n",
    "    #     for span in layer:\n",
    "    #         print(span.layer)\n",
    "    #         print(\"where are u\")\n",
    "    #         if layer.name == 'tokens':\n",
    "    #             # print(layer.name, span.start, span.end, span.text)\n",
    "    #             for span_ in layer:\n",
    "    #                 if len(range(max(span.start, span_.start), min(span.end, span_.end))) > 0:\n",
    "    #                     # print(layer.name)\n",
    "    #                     pass\n",
    "\n",
    "testentry = ResultsEntry(data[2], bert_annotations=['B-SYMP', 'B-DRUG'])\n",
    "testdata = tokenizeForTraining(testentry.text())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable ResultsEntry object",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_52065/1670471432.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     19\u001B[0m \u001B[0mresults\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mPredictionResults\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtasks\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbert_annotations\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'B-SYMP'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'B-DRUG'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 20\u001B[0;31m \u001B[0mmakeFile\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresults\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'fine_tuning_training.tsv'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/tmp/ipykernel_52065/1670471432.py\u001B[0m in \u001B[0;36mmakeFile\u001B[0;34m(prediction_results, training_file)\u001B[0m\n\u001B[1;32m      9\u001B[0m     \u001B[0mwriter\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwriterow\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'text'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'y'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 11\u001B[0;31m     \u001B[0;32mfor\u001B[0m \u001B[0mk\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mv\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mprediction_results\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mentries\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     12\u001B[0m         \u001B[0mtoken\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mv\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m         \u001B[0mlabels\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mv\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: cannot unpack non-iterable ResultsEntry object"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}